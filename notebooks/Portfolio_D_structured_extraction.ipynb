{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio D: Structured Extraction\n",
    "**Turn unstructured text into analyzable data at scale**\n",
    "\n",
    "Researchers often need to extract structured information from messy text \u2014 pulling out entities, claims, metrics, and relationships so they can be counted, filtered, and analyzed in a DataFrame. Your job: build a pipeline that does this reliably using LLMs with schema-enforced output.\n",
    "\n",
    "**Dataset**: You'll work with real-world text (news articles, provided below)\n",
    "**Your goal**: Define a Pydantic schema, extract structured data from multiple documents, and build an analysis on top of the extracted data.\n",
    "\n",
    "### Deliverables\n",
    "- Pydantic schema for your extraction task\n",
    "- Working extraction pipeline with retry logic\n",
    "- Extracted data from 10+ documents in a DataFrame\n",
    "- At least one analysis or visualization built on the extracted data\n",
    "- Brief model card\n",
    "\n",
    "**Estimated time**: Sprint 1 (55 min) + Sprint 2 (90 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai pydantic matplotlib seaborn pandas\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List, Literal, Optional\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API setup\n",
    "GROQ_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
    "    except (ImportError, Exception):\n",
    "        GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\", \"\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "MODEL = \"llama-3.1-8b-instant\"\n",
    "print(\"Groq client ready\" if GROQ_API_KEY else \"WARNING: No API key set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sample Documents\n",
    "Here are a few articles to get started. You can replace these with your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"text\": \"\"\"OpenAI has announced GPT-5, its most capable model yet, claiming a 40% improvement \n",
    "        on reasoning benchmarks over GPT-4. The model was trained on an estimated 15 trillion tokens \n",
    "        and costs approximately $100M to train. CEO Sam Altman stated the model can now pass the bar \n",
    "        exam in the 99th percentile. Microsoft has committed to integrating the model across Office 365 \n",
    "        and Azure. Critics from MIT and Stanford have raised concerns about benchmark contamination.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"text\": \"\"\"Denmark's Ministry of Finance released a report showing that AI adoption in public \n",
    "        administration has increased 23% year-over-year. The report surveyed 450 government agencies \n",
    "        and found that 67% now use AI for document processing. Cost savings are estimated at \n",
    "        DKK 2.1 billion annually. However, only 12% of agencies have formal AI governance policies. \n",
    "        The Danish Data Protection Agency has flagged concerns about automated decision-making in \n",
    "        citizen services.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"text\": \"\"\"A new study in Nature found that transformer-based models can predict protein \n",
    "        structures with 95% accuracy, matching AlphaFold's performance. Researchers from the \n",
    "        University of Cambridge and Google DeepMind collaborated on the project. The model requires \n",
    "        only 2 hours of inference on a single A100 GPU, compared to AlphaFold's 16 hours. The team \n",
    "        plans to release the model weights under an Apache 2.0 license. Pharmaceutical companies \n",
    "        Pfizer and Roche have expressed interest in licensing the technology.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"text\": \"\"\"The European Central Bank warns that AI-driven trading now accounts for \n",
    "        approximately 60% of equity trades in European markets. A report from Deutsche B\\u00f6rse shows \n",
    "        algorithmic trading volume increased 35% in Q3 2025. Regulators are concerned about flash \n",
    "        crash risks, with three notable incidents in the past 6 months. France's AMF has proposed \n",
    "        requiring AI trading systems to include circuit breakers. Goldman Sachs and JP Morgan have \n",
    "        both expanded their AI trading desks by over 200 employees each.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"text\": \"\"\"Spotify's latest earnings report reveals that AI-generated playlists now drive \n",
    "        40% of total listening hours, up from 15% a year ago. The company's recommendation engine, \n",
    "        powered by a custom transformer model, has reduced churn by 18%. Revenue per user increased \n",
    "        12% to \\u20ac5.80/month. CEO Daniel Ek attributed the growth to the AI DJ feature launched in \n",
    "        March 2025. Competitors Apple Music and YouTube Music are reportedly developing similar \n",
    "        features. Spotify's stock rose 8% on the announcement.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(articles)} sample articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Your Schema\n",
    "This is the key design decision \u2014 what structured fields do you want to extract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleExtraction(BaseModel):\n",
    "    title: str = Field(description=\"A concise title for this article (5-10 words)\")\n",
    "    summary: str = Field(description=\"2-3 sentence summary of the key points\")\n",
    "    organizations: List[str] = Field(description=\"Companies, universities, and agencies mentioned\")\n",
    "    key_claims: List[str] = Field(description=\"Main factual claims with numbers (3-5)\")\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\", \"mixed\"] = Field(\n",
    "        description=\"Overall sentiment toward the main topic\"\n",
    "    )\n",
    "    domain: Literal[\"tech\", \"finance\", \"policy\", \"science\", \"culture\"] = Field(\n",
    "        description=\"Primary domain of the article\"\n",
    "    )\n",
    "\n",
    "# Test that the schema compiles\n",
    "print(json.dumps(ArticleExtraction.model_json_schema(), indent=2)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract from One Document (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article(text: str, max_retries: int = 3) -> Optional[ArticleExtraction]:\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": (\n",
    "                        \"Extract structured information from the article. \"\n",
    "                        \"Return valid JSON matching the schema. Do not invent facts.\"\n",
    "                    )},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                temperature=0.0,\n",
    "                max_tokens=500,\n",
    "            )\n",
    "            return ArticleExtraction.model_validate_json(response.choices[0].message.content)\n",
    "        except (ValidationError, Exception) as e:\n",
    "            print(f\"  Attempt {attempt+1} failed: {e}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    return None\n",
    "\n",
    "# Test on first article\n",
    "result = extract_article(articles[0][\"text\"])\n",
    "if result:\n",
    "    print(f\"Title: {result.title}\")\n",
    "    print(f\"Domain: {result.domain}\")\n",
    "    print(f\"Sentiment: {result.sentiment}\")\n",
    "    print(f\"Organizations: {result.organizations}\")\n",
    "    print(f\"Key claims:\")\n",
    "    for claim in result.key_claims:\n",
    "        print(f\"  - {claim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "extractions = []\n",
    "for article in tqdm(articles, desc=\"Extracting\"):\n",
    "    result = extract_article(article[\"text\"])\n",
    "    if result:\n",
    "        row = result.model_dump()\n",
    "        row[\"id\"] = article[\"id\"]\n",
    "        extractions.append(row)\n",
    "    time.sleep(0.5)  # Rate limiting\n",
    "\n",
    "extract_df = pd.DataFrame(extractions)\n",
    "print(f\"\\nSuccessfully extracted: {len(extract_df)}/{len(articles)}\")\n",
    "extract_df[[\"id\", \"title\", \"domain\", \"sentiment\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze the Extracted Data\n",
    "Now that you have structured data, analyze it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: domain distribution\n",
    "print(\"Domain distribution:\")\n",
    "print(extract_df[\"domain\"].value_counts())\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(extract_df[\"sentiment\"].value_counts())\n",
    "\n",
    "# Organizations mentioned\n",
    "all_orgs = [org for orgs in extract_df[\"organizations\"] for org in orgs]\n",
    "print(f\"\\nAll organizations mentioned ({len(all_orgs)} total):\")\n",
    "print(pd.Series(all_orgs).value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Your Turn: Scale Up & Extend\n",
    "\n",
    "Ideas:\n",
    "- **Add more articles**: Find 10+ articles on a topic you care about (paste them in or load from a dataset)\n",
    "- **Richer schema**: Add fields like `risk_factors`, `monetary_amounts`, `date_references`\n",
    "- **Cross-document analysis**: Which organizations appear most? What's the overall sentiment trend?\n",
    "- **Visualization**: Plot extracted metrics, build a network of organization co-mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE \u2014 extend the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Card\n",
    "\n",
    "| Field | Value |\n",
    "|-------|-------|\n",
    "| **Task** | Structured extraction from text |\n",
    "| **LLM** | _model name_ |\n",
    "| **Schema fields** | _list your fields_ |\n",
    "| **Documents processed** | _N_ |\n",
    "| **Success rate** | _% extracted without errors_ |\n",
    "| **Key insight** | _what did the extracted data reveal?_ |\n",
    "| **Failure mode** | _what does the LLM get wrong?_ |\n",
    "| **Improvement idea** | _what you'd try next_ |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
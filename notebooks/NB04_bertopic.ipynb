{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB04: BERTopic — Topic Discovery + LLM Annotation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RJuro/unistra-nlp2026/blob/main/notebooks/NB04_bertopic.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Learning Goals**\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "\n",
    "- **Discover latent topics** in text collections without any labels using BERTopic\n",
    "- **Configure BERTopic components** — embeddings, UMAP, HDBSCAN, and vectorizer — to control topic quality\n",
    "- **Use LLMs to name topics** via the Groq API, replacing cryptic keyword lists with human-readable labels\n",
    "- **Visualize and interpret topic models** with interactive charts, document maps, and hierarchies\n",
    "\n",
    "**Estimated time:** ~90 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Setup ──────────────────────────────────────────────────────────────────\n",
    "# Install dependencies (Colab-friendly)\n",
    "!pip install bertopic[visualization] sentence-transformers umap-learn hdbscan openai pandas numpy scikit-learn datasets -q\n",
    "\n",
    "# Core\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Dimensionality reduction & clustering\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# Sentence embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# BERTopic\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# LLM client (OpenAI-compatible)\n",
    "from openai import OpenAI\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"All imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Dataset: Moltbook\n",
    "\n",
    "**Moltbook** is a dataset of ~44K posts from an AI agent social network — think of it as a leaked database from the front page of the agent internet. The posts were generated by LLM-powered agents interacting in a simulated social platform, complete with submolts (like subreddits), upvotes, and comments.\n",
    "\n",
    "Each post is annotated with:\n",
    "- **9 content categories** (`topic_label`: A through I)\n",
    "- **5 toxicity levels** (`toxic_level`: 0–4)\n",
    "\n",
    "Our goal: **ignore the labels entirely** and see whether BERTopic can rediscover meaningful topic structure from the raw text alone. Then we will use an LLM to give those discovered topics human-readable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load Moltbook from HuggingFace ──────────────────────────────────────\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"TrustAIRLab/Moltbook\", \"posts\", split=\"train\")\n",
    "df = dataset.to_pandas()\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nSample post:\")\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Flatten the nested 'post' column and extract text ─────────────\n",
    "# The dataset has a nested 'post' dict with 'title' and 'content' keys\n",
    "df[\"title\"] = df[\"post\"].apply(lambda x: x.get(\"title\", \"\") if isinstance(x, dict) else \"\")\n",
    "df[\"content\"] = df[\"post\"].apply(lambda x: x.get(\"content\", \"\") if isinstance(x, dict) else \"\")\n",
    "df[\"text\"] = df[\"title\"] + \" . \" + df[\"content\"]\n",
    "\n",
    "print(f\"Topic label distribution:\\n{df['topic_label'].value_counts()}\")\n",
    "print(f\"\\nToxic level distribution:\\n{df['toxic_level'].value_counts()}\")\n",
    "print(f\"\\n--- Example text ---\")\n",
    "print(df[\"text\"].iloc[0][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Subsample for speed ────────────────────────────────────────────\n",
    "# 5000 posts is enough to find meaningful topics while keeping runtime short\n",
    "df_sample = df.sample(5000, random_state=42).reset_index(drop=True)\n",
    "print(f\"Working with {len(df_sample)} posts\")\n",
    "print(f\"Topic labels in sample: {sorted(df_sample['topic_label'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing\n",
    "\n",
    "We apply minimal cleaning: lowercase, remove URLs, and collapse whitespace. BERTopic relies on semantic embeddings, so aggressive preprocessing (stemming, removing punctuation) can actually hurt by destroying meaning that the embedding model understands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Simple text cleaning ───────────────────────────────────────────\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Lowercase, remove URLs, and collapse whitespace.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https?://\\S+\", \"\", text)  # remove URLs\n",
    "    text = re.sub(r\"\\s+\", \" \", text)           # collapse whitespace\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df_sample[\"text_clean\"] = df_sample[\"text\"].apply(clean_text)\n",
    "\n",
    "# Before / after\n",
    "print(\"BEFORE cleaning:\")\n",
    "print(df_sample[\"text\"].iloc[0][:200])\n",
    "print()\n",
    "print(\"AFTER cleaning:\")\n",
    "print(df_sample[\"text_clean\"].iloc[0][:200])\n",
    "print(f\"\\nAverage text length: {df_sample['text_clean'].str.len().mean():.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating Embeddings\n",
    "\n",
    "BERTopic needs **dense vector embeddings** to find semantic clusters. We use `all-MiniLM-L6-v2`, a fast sentence-transformer that maps each text to a 384-dimensional vector. Documents that are semantically similar end up close together in this vector space.\n",
    "\n",
    "We pre-compute embeddings separately so we can reuse them across experiments without re-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Generate sentence embeddings ──────────────────────────────────\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = embedding_model.encode(\n",
    "    df_sample[\"text_clean\"].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuring BERTopic Components\n",
    "\n",
    "BERTopic is a **modular pipeline**. Each step can be configured independently:\n",
    "\n",
    "1. **Embeddings** → dense vectors from a sentence transformer (already done above)\n",
    "2. **UMAP** → reduces the 384-dimensional embeddings to 5 dimensions while preserving local structure\n",
    "3. **HDBSCAN** → finds density-based clusters in the reduced space (no need to specify *k*)\n",
    "4. **CountVectorizer** → extracts the most representative words per cluster using c-TF-IDF\n",
    "5. **Representation model** → refines topic keywords (we use KeyBERTInspired for coherent labels)\n",
    "\n",
    "### Key parameters to understand\n",
    "\n",
    "| Component | Parameter | Effect |\n",
    "|---|---|---|\n",
    "| UMAP | `n_neighbors` | Higher = more global structure, lower = more local detail |\n",
    "| UMAP | `n_components` | Dimensions for HDBSCAN (5 is a good default) |\n",
    "| HDBSCAN | `min_cluster_size` | Minimum documents per topic (higher = fewer, larger topics) |\n",
    "| CountVectorizer | `stop_words` | Words to exclude from topic representations |\n",
    "| CountVectorizer | `ngram_range` | (1,2) captures both single words and bigrams |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configure BERTopic components ─────────────────────────────────\n",
    "\n",
    "# Custom stopwords: English defaults + common filler words\n",
    "stopwords = list(ENGLISH_STOP_WORDS) + [\n",
    "    \"just\", \"like\", \"really\", \"think\", \"know\", \"want\",\n",
    "    \"got\", \"get\", \"one\", \"would\", \"could\", \"also\",\n",
    "    \"even\", \"much\", \"way\", \"thing\", \"things\", \"make\",\n",
    "]\n",
    "\n",
    "# Vectorizer: unigrams + bigrams, minimum 3 documents\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words=stopwords,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    ")\n",
    "\n",
    "# UMAP: reduce to 5 dimensions, cosine distance\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=5,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# HDBSCAN: density-based clustering, no need to specify k\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=15,\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\",\n",
    "    prediction_data=True,\n",
    ")\n",
    "\n",
    "# Representation: KeyBERT-inspired for more coherent topic keywords\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "print(\"Components configured:\")\n",
    "print(f\"  Vectorizer:      CountVectorizer(ngram_range=(1,2), min_df=3)\")\n",
    "print(f\"  UMAP:            n_neighbors=15, n_components=5, metric='cosine'\")\n",
    "print(f\"  HDBSCAN:         min_cluster_size=15, metric='euclidean', method='eom'\")\n",
    "print(f\"  Representation:  KeyBERTInspired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Topic Model\n",
    "\n",
    "Now we assemble the components into a BERTopic model and run `fit_transform`. Since we already pre-computed embeddings, we pass them directly — BERTopic skips the embedding step and goes straight to UMAP + HDBSCAN.\n",
    "\n",
    "The output is:\n",
    "- `topics`: a list of topic IDs (one per document). Topic `-1` = outlier (not assigned to any topic).\n",
    "- `probs`: soft assignment probabilities for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Build and train BERTopic ───────────────────────────────────────\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    representation_model=representation_model,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(\n",
    "    df_sample[\"text_clean\"].tolist(),\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "\n",
    "print(f\"\\nNumber of topics found: {len(set(topics)) - 1}\")  # -1 for outlier topic\n",
    "print(f\"Outlier documents: {sum(t == -1 for t in topics)} ({sum(t == -1 for t in topics)/len(topics)*100:.1f}%)\")\n",
    "print(f\"Assigned documents: {sum(t != -1 for t in topics)} ({sum(t != -1 for t in topics)/len(topics)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploring Topics\n",
    "\n",
    "BERTopic provides multiple ways to inspect the discovered topics. Let's start with the **topic info table**, which shows each topic's size and representative keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Topic info table ──────────────────────────────────────────────\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(f\"Total topics (including outliers): {len(topic_info)}\")\n",
    "print()\n",
    "print(topic_info.head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualize topics: bar chart of top keywords ─────────────────\n",
    "topic_model.visualize_barchart(top_n_topics=15, n_words=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualize topic map (intertopic distance) ───────────────────\n",
    "# Each circle is a topic; size = number of documents; distance = similarity\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualize documents in 2D ─────────────────────────────────────\n",
    "# Each dot is a document, colored by topic assignment\n",
    "topic_model.visualize_documents(\n",
    "    df_sample[\"text_clean\"].tolist(),\n",
    "    embeddings=embeddings,\n",
    "    hide_annotations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Topic hierarchy (dendrogram) ─────────────────────────────────\n",
    "# Shows how topics relate to each other and could be merged\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LLM-Powered Topic Naming\n",
    "\n",
    "The keyword-based topic names from BERTopic are functional but not always intuitive. An LLM can read the keywords **and** a few representative documents, then generate a concise, descriptive label.\n",
    "\n",
    "We use **Groq** (fast inference for open-source LLMs) with an OpenAI-compatible API. The pattern:\n",
    "1. For each topic, collect its top keywords and representative documents\n",
    "2. Send them to the LLM with a prompt asking for a 3-6 word label\n",
    "3. Update the BERTopic model with the new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Set up Groq client ────────────────────────────────────────────\n",
    "GROQ_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "groq_client = OpenAI(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Generate LLM topic names ──────────────────────────────────────\n",
    "\n",
    "def name_topic_with_llm(topic_id, topic_model, groq_client, n_docs=5):\n",
    "    \"\"\"Use an LLM to generate a descriptive topic name.\"\"\"\n",
    "    # Get topic keywords\n",
    "    topic_words = topic_model.get_topic(topic_id)\n",
    "    keywords = [w for w, _ in topic_words[:10]]\n",
    "\n",
    "    # Get representative documents\n",
    "    repr_docs = topic_model.get_representative_docs(topic_id)\n",
    "    docs_text = \"\\n---\\n\".join(repr_docs[:n_docs])\n",
    "\n",
    "    prompt = f\"\"\"Based on the following keywords and representative documents from a topic cluster, \n",
    "generate a short, descriptive topic label (3-6 words).\n",
    "\n",
    "Keywords: {', '.join(keywords)}\n",
    "\n",
    "Representative documents:\n",
    "{docs_text}\n",
    "\n",
    "Return ONLY the topic label, nothing else.\"\"\"\n",
    "\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=20,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Name top 10 topics (skip topic -1 which is outliers)\n",
    "n_topics_to_name = min(10, len(topic_info) - 1)  # -1 to exclude outlier row\n",
    "\n",
    "topic_names = {}\n",
    "for topic_id in range(n_topics_to_name):\n",
    "    name = name_topic_with_llm(topic_id, topic_model, groq_client)\n",
    "    topic_names[topic_id] = name\n",
    "    print(f\"Topic {topic_id}: {name}\")\n",
    "    time.sleep(0.3)  # respect rate limits\n",
    "\n",
    "print(f\"\\nNamed {len(topic_names)} topics with LLM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Update model with LLM-generated names ───────────────────────\n",
    "topic_model.set_topic_labels(topic_names)\n",
    "\n",
    "# Re-visualize with the new labels\n",
    "topic_model.visualize_barchart(top_n_topics=10, n_words=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparing Topics to Ground Truth\n",
    "\n",
    "Moltbook posts have ground-truth `topic_label` categories (A-I). Topic modeling is **unsupervised** — it does not know about these labels. But we can check whether the discovered topics align with the known categories using a cross-tabulation.\n",
    "\n",
    "A strong alignment means BERTopic found meaningful structure. Mismatches might reveal sub-topics within categories or cross-cutting themes that span multiple categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Cross-tabulation: discovered topics vs ground truth ───────────\n",
    "df_sample[\"topic\"] = topics\n",
    "\n",
    "if \"topic_label\" in df_sample.columns:\n",
    "    # Show cross-tab for top 15 topics (excluding outliers)\n",
    "    df_assigned = df_sample[df_sample[\"topic\"] != -1].copy()\n",
    "\n",
    "    # Limit to top 15 topics by size for readability\n",
    "    top_topics = df_assigned[\"topic\"].value_counts().head(15).index.tolist()\n",
    "    df_top = df_assigned[df_assigned[\"topic\"].isin(top_topics)]\n",
    "\n",
    "    ct = pd.crosstab(\n",
    "        df_top[\"topic_label\"],\n",
    "        df_top[\"topic\"],\n",
    "        margins=True,\n",
    "    )\n",
    "    print(\"Cross-tabulation: Ground-truth category (rows) vs BERTopic topic (columns)\")\n",
    "    print()\n",
    "    print(ct.to_string())\n",
    "else:\n",
    "    print(\"No 'topic_label' column found -- skipping comparison.\")\n",
    "    print(\"Topic distribution:\")\n",
    "    print(df_sample[\"topic\"].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercise: Tune the Model\n",
    "\n",
    "BERTopic is sensitive to its hyperparameters. Your task: **change one or more settings and observe the effect on topic quality.**\n",
    "\n",
    "Suggestions to try:\n",
    "- **`min_cluster_size`**: try 10, 20, or 50. Smaller values = more fine-grained topics, larger = fewer broader topics.\n",
    "- **`n_neighbors`**: try 5, 15, or 30. Controls UMAP's balance between local and global structure.\n",
    "- **`n_components`**: try 3 or 10 instead of 5.\n",
    "- **Embedding model**: try `\"all-mpnet-base-v2\"` (larger, more accurate) or `\"paraphrase-MiniLM-L3-v2\"` (faster, less accurate).\n",
    "- **`ngram_range`**: try `(1, 3)` for trigrams.\n",
    "\n",
    "Compare: How many topics are found? How many outliers? Do the topic keywords look more or less coherent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── YOUR CODE HERE ─────────────────────────────────────────────────\n",
    "# Step 1: Change one or more parameters below\n",
    "\n",
    "# umap_model_v2 = UMAP(\n",
    "#     n_neighbors=??,       # try 5, 15, 30\n",
    "#     n_components=??,      # try 3, 5, 10\n",
    "#     metric=\"cosine\",\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "# hdbscan_model_v2 = HDBSCAN(\n",
    "#     min_cluster_size=??,  # try 10, 20, 50\n",
    "#     metric=\"euclidean\",\n",
    "#     cluster_selection_method=\"eom\",\n",
    "#     prediction_data=True,\n",
    "# )\n",
    "\n",
    "# Step 2: Build and fit a new topic model\n",
    "\n",
    "# topic_model_v2 = BERTopic(\n",
    "#     embedding_model=embedding_model,\n",
    "#     vectorizer_model=vectorizer,\n",
    "#     umap_model=umap_model_v2,\n",
    "#     hdbscan_model=hdbscan_model_v2,\n",
    "#     representation_model=KeyBERTInspired(),\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# topics_v2, probs_v2 = topic_model_v2.fit_transform(\n",
    "#     df_sample[\"text_clean\"].tolist(),\n",
    "#     embeddings=embeddings,\n",
    "# )\n",
    "\n",
    "# Step 3: Compare\n",
    "# print(f\"Number of topics: {len(set(topics_v2)) - 1}\")\n",
    "# print(f\"Outliers: {sum(t == -1 for t in topics_v2)}\")\n",
    "# topic_model_v2.get_topic_info().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Summary & Takeaways\n\n### What we learned\n\n1. **BERTopic discovers topics without labels.** It combines sentence embeddings, dimensionality reduction (UMAP), and density-based clustering (HDBSCAN) to find groups of semantically similar documents.\n\n2. **LLMs dramatically improve topic naming.** Instead of reading keyword lists like `[\"climate\", \"carbon\", \"emissions\", \"energy\"]`, an LLM can produce labels like \"Climate Change & Carbon Policy\" — much easier for humans to interpret.\n\n3. **Key parameters to tune:**\n   - `min_cluster_size` controls topic granularity (most impactful parameter)\n   - `n_neighbors` balances local vs global structure in UMAP\n   - The embedding model determines the quality of the semantic space\n\n4. **When to use topic modeling in research:**\n   - Exploratory analysis of large text corpora\n   - Discovering themes in survey responses, reviews, or social media\n   - Content analysis where manual coding is too expensive\n   - As a preprocessing step: topic assignments can become features for downstream tasks\n\n### The BERTopic pipeline at a glance\n\n![BERTopic Pipeline](https://raw.githubusercontent.com/RJuro/unistra-nlp2026/main/notebooks/figures/bertopic_pipeline.png)\n\n### Next steps\n\n- Try **topic merging** with `topic_model.merge_topics()` to combine related topics\n- Explore **dynamic topic modeling** for temporal analysis\n- Use discovered topics as **features in a classifier** (semi-supervised approach)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
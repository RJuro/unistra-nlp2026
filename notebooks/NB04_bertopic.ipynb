{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB04: BERTopic — Topic Discovery + LLM Annotation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RJuro/unistra-nlp2026/blob/main/notebooks/NB04_bertopic.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Learning Goals**\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "\n",
    "- **Frame topic modeling as a real analysis task** (not just a demo): separate high-signal discourse from platform-specific noise\n",
    "- **Discover latent topics** in text collections without labels using BERTopic\n",
    "- **Tune BERTopic components** (embeddings, UMAP, HDBSCAN, vectorizer) and explain what each knob changes\n",
    "- **Refine a mega-topic into useful sub-clusters** with an inspect -> filter -> re-cluster workflow\n",
    "- **Use LLM-based topic naming** to make clusters interpretable for human reporting\n",
    "- **Produce both static and interactive topic maps** with DataMapPlot for slides and exploratory analysis\n",
    "\n",
    "> 2026 refresh: this notebook follows BERTopic best practices (`reduce_outliers`, DataMapPlot export) and uses compact IntFloat multilingual E5 embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Setup ──────────────────────────────────────────────────────────────────\n",
    "# Install dependencies (Colab-friendly)\n",
    "!pip install bertopic[visualization] sentence-transformers umap-learn hdbscan openai pandas numpy scikit-learn datasets datamapplot -q\n",
    "\n",
    "# Core\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Dimensionality reduction & clustering\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# Sentence embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# BERTopic\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# LLM client (OpenAI-compatible)\n",
    "from openai import OpenAI\n",
    "\n",
    "print(\"All imports successful.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── GPU Check ─────────────────────────────────────────────────────────────\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU detected — running on CPU.\")\n",
    "    print(\"Embedding 5,000 documents will take ~5 minutes instead of ~30 seconds.\")\n",
    "    print(\"To enable GPU: Runtime → Change runtime type → T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Dataset: Moltbook\n",
    "\n",
    "**Moltbook** is a dataset of ~44K posts from an AI-agent social network simulation.\n",
    "\n",
    "Why this is a strong real-world case:\n",
    "- It contains **community structure** (submolts) similar to real forums.\n",
    "- It mixes broad shared discourse with **small insular micro-communities**.\n",
    "- It has latent topic overlap, slang, and multilingual content that stress-tests unsupervised models.\n",
    "\n",
    "In practice, analysts face this exact problem: identify high-signal thematic clusters while avoiding over-interpreting tiny, self-referential pockets.\n",
    "\n",
    "For this notebook, we will explicitly inspect:\n",
    "- **Core-0 communities** (often broad and internally diverse, good candidates for sub-clustering)\n",
    "- **Tiny insular communities** (often repetitive/noisy and likely to produce brittle micro-topics)\n",
    "\n",
    "Each post also has ground-truth labels (`topic_label`, `toxic_level`) that we ignore during modeling and use only for post-hoc sanity checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load Moltbook from HuggingFace ──────────────────────────────────────\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"TrustAIRLab/Moltbook\", \"posts\", split=\"train\")\n",
    "df = dataset.to_pandas()\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nSample post:\")\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Flatten the nested 'post' column and extract text ─────────────\n",
    "# The dataset has a nested 'post' dict with 'title', 'content', and 'submolt' keys.\n",
    "df[\"title\"] = df[\"post\"].apply(lambda x: x.get(\"title\", \"\") if isinstance(x, dict) else \"\")\n",
    "df[\"content\"] = df[\"post\"].apply(lambda x: x.get(\"content\", \"\") if isinstance(x, dict) else \"\")\n",
    "df[\"submolt\"] = df[\"post\"].apply(\n",
    "    lambda x: x.get(\"submolt\", {}).get(\"name\", \"\") if isinstance(x, dict) else \"\"\n",
    ")\n",
    "\n",
    "# Fill NaN values and ensure string types\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\").astype(str)\n",
    "df[\"content\"] = df[\"content\"].fillna(\"\").astype(str)\n",
    "df[\"submolt\"] = df[\"submolt\"].fillna(\"\").astype(str)\n",
    "\n",
    "df[\"text\"] = (df[\"title\"].str.strip() + \" . \" + df[\"content\"].str.strip()).str.strip()\n",
    "df = df[df[\"text\"].str.len() > 3].reset_index(drop=True)\n",
    "\n",
    "# Normalize submolt names for robust matching\n",
    "df[\"submolt_norm\"] = (\n",
    "    df[\"submolt\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[_\\-]+\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Community-level features used later for pedagogy + filtering\n",
    "df[\"is_core0\"] = df[\"submolt_norm\"].str.contains(r\"\\bcore\\s*0\\b\", regex=True, na=False)\n",
    "df[\"is_insular\"] = df[\"submolt_norm\"].str.contains(r\"\\binsular\\b\", regex=True, na=False)\n",
    "\n",
    "submolt_sizes = df[\"submolt_norm\"].value_counts()\n",
    "df[\"submolt_size\"] = df[\"submolt_norm\"].map(submolt_sizes).fillna(0).astype(int)\n",
    "\n",
    "print(f\"Posts with valid text: {len(df)}\")\n",
    "print(\"\\nTop communities by size:\")\n",
    "print(df[\"submolt_norm\"].value_counts().head(12))\n",
    "\n",
    "print(\"\\nCommunity diagnostics:\")\n",
    "print(f\"  Core-0 posts: {df['is_core0'].sum()} ({df['is_core0'].mean()*100:.1f}%)\")\n",
    "print(f\"  Insular posts: {df['is_insular'].sum()} ({df['is_insular'].mean()*100:.1f}%)\")\n",
    "print(f\"  Tiny communities (<=25 posts): {(submolt_sizes <= 25).sum()}\")\n",
    "\n",
    "print(\"\\n--- Example text ---\")\n",
    "print(df[\"text\"].iloc[0][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Filter platform artifacts + tiny insular noise ─────────────────\n",
    "# We keep this filtering conservative and explicit:\n",
    "# 1) remove greeting-only intro chatter\n",
    "# 2) remove tiny insular communities (often repetitive/noisy)\n",
    "# 3) keep a strong Core-0 presence so BERTopic can split it into sub-topics\n",
    "\n",
    "before = len(df)\n",
    "\n",
    "greeting_mask = (\n",
    "    (df[\"submolt_norm\"] == \"introductions\")\n",
    "    | df[\"text\"].str.contains(r\"\\bhello\\s+world\\b\", case=False, na=False)\n",
    ")\n",
    "\n",
    "tiny_insular_threshold = 25\n",
    "tiny_insular_mask = df[\"is_insular\"] & (df[\"submolt_size\"] <= tiny_insular_threshold)\n",
    "\n",
    "remove_mask = greeting_mask | tiny_insular_mask\n",
    "df = df[~remove_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"Filtered: {before} → {len(df)} posts\")\n",
    "print(f\"  Removed greetings/introductions: {int(greeting_mask.sum())}\")\n",
    "print(f\"  Removed tiny insular posts:      {int(tiny_insular_mask.sum())}\")\n",
    "\n",
    "# ── Focused subsample for speed (while preserving Core-0 coverage) ──\n",
    "def focused_sample(frame, n=5000, core_share=0.40, seed=42):\n",
    "    n = min(n, len(frame))\n",
    "    core = frame[frame[\"is_core0\"]]\n",
    "    non_core = frame[~frame[\"is_core0\"]]\n",
    "\n",
    "    n_core = min(int(n * core_share), len(core))\n",
    "    n_non_core = min(n - n_core, len(non_core))\n",
    "\n",
    "    chunks = []\n",
    "    if n_core > 0:\n",
    "        chunks.append(core.sample(n=n_core, random_state=seed))\n",
    "    if n_non_core > 0:\n",
    "        chunks.append(non_core.sample(n=n_non_core, random_state=seed))\n",
    "\n",
    "    sampled = pd.concat(chunks) if chunks else frame.sample(n=n, random_state=seed)\n",
    "\n",
    "    if len(sampled) < n:\n",
    "        remaining = frame.drop(sampled.index, errors=\"ignore\")\n",
    "        extra = remaining.sample(n=n - len(sampled), random_state=seed)\n",
    "        sampled = pd.concat([sampled, extra])\n",
    "\n",
    "    return sampled.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_sample = focused_sample(df, n=5000, core_share=0.40, seed=42)\n",
    "\n",
    "print(f\"\\nWorking sample: {len(df_sample)} posts\")\n",
    "print(f\"  Core-0 in sample: {df_sample['is_core0'].mean()*100:.1f}%\")\n",
    "print(f\"  Insular in sample: {df_sample['is_insular'].mean()*100:.1f}%\")\n",
    "print(f\"  Topic labels present: {sorted(df_sample['topic_label'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing\n",
    "\n",
    "We apply minimal cleaning: lowercase, remove URLs, and collapse whitespace. BERTopic relies on semantic embeddings, so aggressive preprocessing (stemming, removing punctuation) can actually hurt by destroying meaning that the embedding model understands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Simple text cleaning ───────────────────────────────────────────\n",
    "def clean_text(text) -> str:\n",
    "    \"\"\"Lowercase, remove URLs, and collapse whitespace. Handles NaN/float gracefully.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https?://\\S+\", \"\", text)  # remove URLs\n",
    "    text = re.sub(r\"\\s+\", \" \", text)           # collapse whitespace\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df_sample[\"text_clean\"] = df_sample[\"text\"].apply(clean_text)\n",
    "\n",
    "# Drop any rows that ended up empty after cleaning\n",
    "df_sample = df_sample[df_sample[\"text_clean\"].str.len() > 3].reset_index(drop=True)\n",
    "\n",
    "# Before / after\n",
    "print(\"BEFORE cleaning:\")\n",
    "print(df_sample[\"text\"].iloc[0][:200])\n",
    "print()\n",
    "print(\"AFTER cleaning:\")\n",
    "print(df_sample[\"text_clean\"].iloc[0][:200])\n",
    "print(f\"\\nSample size after cleaning: {len(df_sample)}\")\n",
    "print(f\"Average text length: {df_sample['text_clean'].str.len().mean():.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating Embeddings\n",
    "\n",
    "BERTopic needs dense embeddings to identify semantic neighborhoods before clustering.\n",
    "\n",
    "Because Moltbook includes multilingual content, we use:\n",
    "\n",
    "- `intfloat/multilingual-e5-small` (compact multilingual retrieval model)\n",
    "\n",
    "Why this model is a good fit here:\n",
    "- compact enough for classroom workflows\n",
    "- multilingual support for mixed-language corpora\n",
    "- strong semantic separation when we format texts as E5 passages\n",
    "\n",
    "Important E5 detail: format each document as `\"passage: ...\"` before encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Generate sentence embeddings (IntFloat multilingual E5) ───────\n",
    "EMBED_MODEL_NAME = \"intfloat/multilingual-e5-small\"\n",
    "embedding_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
    "\n",
    "\n",
    "def format_passage(text: str) -> str:\n",
    "    return f\"passage: {text.strip()}\"\n",
    "\n",
    "\n",
    "embedding_inputs = [format_passage(t) for t in df_sample[\"text_clean\"].tolist()]\n",
    "\n",
    "embeddings = embedding_model.encode(\n",
    "    embedding_inputs,\n",
    "    show_progress_bar=True,\n",
    "    batch_size=64,\n",
    "    normalize_embeddings=True,\n",
    ")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Model: {EMBED_MODEL_NAME}\")\n",
    "print(\"E5 formatting: using 'passage:' prefix for all documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuring BERTopic Components\n",
    "\n",
    "BERTopic is modular:\n",
    "1. **Embeddings** (semantic vectors)\n",
    "2. **UMAP** (dimensionality reduction)\n",
    "3. **HDBSCAN** (density clustering)\n",
    "4. **c-TF-IDF + representation model** (topic words/labels)\n",
    "\n",
    "Key knobs from official BERTopic guidance:\n",
    "- **`min_topic_size` / `min_cluster_size`** controls granularity (small = finer, large = broader)\n",
    "- **UMAP `min_dist=0.0`** often helps density clustering by packing neighborhoods tightly\n",
    "- **Outliers are expected** and should be handled explicitly (`reduce_outliers` strategies)\n",
    "\n",
    "For this case, we start fairly fine-grained, then refine after inspecting topic diagnostics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configure BERTopic components ─────────────────────────────────\n",
    "\n",
    "# Custom stopwords: English defaults + common filler words + DOMAIN-SPECIFIC terms.\n",
    "# Since this is an AI agent social network, words like \"ai\", \"agent\", \"agents\"\n",
    "# appear in nearly every post and overwhelm topic keywords if not removed.\n",
    "stopwords = list(ENGLISH_STOP_WORDS) + [\n",
    "    # Common filler words\n",
    "    \"just\", \"like\", \"really\", \"think\", \"know\", \"want\",\n",
    "    \"got\", \"get\", \"one\", \"would\", \"could\", \"also\",\n",
    "    \"even\", \"much\", \"way\", \"thing\", \"things\", \"make\",\n",
    "    \"going\", \"need\", \"new\", \"use\", \"using\", \"used\",\n",
    "    # Moltbook domain words (appear in almost every post — not discriminative)\n",
    "    \"ai\", \"agent\", \"agents\", \"moltbook\", \"post\", \"posts\",\n",
    "    \"bot\", \"bots\", \"human\", \"humans\", \"world\", \"hello\",\n",
    "    \"sub\", \"submolt\", \"hackerclaw\", \"todos\",\n",
    "]\n",
    "\n",
    "# Vectorizer: unigrams + bigrams, require term in at least 5 docs\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words=stopwords,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,             # raised from 3 — filters out very rare terms\n",
    ")\n",
    "\n",
    "# UMAP: reduce to 5 dimensions for clustering\n",
    "# Best practice: min_dist=0.0 produces tighter clusters for HDBSCAN\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=5,\n",
    "    min_dist=0.0,          # ← best practice: pack points tighter for density clustering\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# HDBSCAN: intentionally fine-grained — we'll refine in Section 7\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=15,   # lower value captures fine-grained patterns (we refine later)\n",
    "    min_samples=10,        # makes cluster cores denser, reduces noise topics\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\",\n",
    "    prediction_data=True,\n",
    ")\n",
    "\n",
    "# Representation: KeyBERT-inspired for more coherent topic keywords\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "print(\"Components configured:\")\n",
    "print(f\"  Vectorizer:      CountVectorizer(ngram_range=(1,2), min_df=5, +domain stopwords)\")\n",
    "print(f\"  UMAP:            n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine'\")\n",
    "print(f\"  HDBSCAN:         min_cluster_size=15, min_samples=10, method='eom'\")\n",
    "print(f\"  Representation:  KeyBERTInspired\")\n",
    "print(f\"\\nNote: min_cluster_size=15 produces many fine-grained topics.\")\n",
    "print(f\"We will inspect and re-cluster in Section 7.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Topic Model\n",
    "\n",
    "Now we assemble the components into a BERTopic model and run `fit_transform`. Since we already pre-computed embeddings, we pass them directly — BERTopic skips the embedding step and goes straight to UMAP + HDBSCAN.\n",
    "\n",
    "The output is:\n",
    "- `topics`: a list of topic IDs (one per document). Topic `-1` = outlier (not assigned to any topic).\n",
    "- `probs`: soft assignment probabilities for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Build and train BERTopic ───────────────────────────────────────\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    representation_model=representation_model,\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(\n",
    "    df_sample[\"text_clean\"].tolist(),\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "\n",
    "print(f\"\\nNumber of topics found: {len(set(topics)) - (1 if -1 in topics else 0)}\")\n",
    "outliers = sum(t == -1 for t in topics)\n",
    "print(f\"Outlier documents: {outliers} ({outliers/len(topics)*100:.1f}%)\")\n",
    "print(f\"Assigned documents: {sum(t != -1 for t in topics)} ({sum(t != -1 for t in topics)/len(topics)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploring Topics\n",
    "\n",
    "BERTopic provides multiple ways to inspect the discovered topics. Let's start with the **topic info table**, which shows each topic's size and representative keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Topic info table ──────────────────────────────────────────────\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(f\"Total topics (including outliers): {len(topic_info)}\")\n",
    "print()\n",
    "print(topic_info.head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualize topics: bar chart of top keywords ─────────────────\n",
    "topic_model.visualize_barchart(top_n_topics=15, n_words=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualize topic map (intertopic distance) ───────────────────\n",
    "# Each circle is a topic; size = number of documents; distance = similarity\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualize documents in 2D ─────────────────────────────────────\n",
    "# Pre-compute 2D embeddings for FAST visualization (best practice).\n",
    "# This is a separate UMAP from the 5D one used for clustering —\n",
    "# here we reduce to 2D purely for plotting, with tighter packing.\n",
    "reduced_embeddings = UMAP(\n",
    "    n_neighbors=10, n_components=2, min_dist=0.0, metric=\"cosine\", random_state=42\n",
    ").fit_transform(embeddings)\n",
    "\n",
    "# Each dot is a document, colored by topic assignment\n",
    "topic_model.visualize_documents(\n",
    "    df_sample[\"text_clean\"].tolist(),\n",
    "    reduced_embeddings=reduced_embeddings,  # ← pre-reduced = instant rendering\n",
    "    hide_annotations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Topic hierarchy (dendrogram) ─────────────────────────────────\n# Shows how topics relate to each other and could be merged.\n# Note: This can fail when cosine similarities produce negative distances.\ntry:\n    topic_model.visualize_hierarchy()\nexcept ValueError as e:\n    if \"negative\" in str(e).lower():\n        print(f\"⚠ visualize_hierarchy() skipped: {e}\")\n        print(\"  Cosine similarity can produce negative distance values that\")\n        print(\"  scipy's hierarchical clustering cannot handle.\")\n        print(\"  This is a known limitation — other visualizations work fine.\")\n    else:\n        raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Refining Topics: Spatial Filtering via the Mega-Topic\n\nA first BERTopic pass on a dataset like Moltbook often produces:\n- one **very large topic** in the center (the \"mega-topic\" — broad, mixed discourse)\n- several **small scattered clusters** far away (niche communities, spam, platform artifacts)\n- a cloud of **outliers** (`-1`)\n\nThe mega-topic is the one we actually want to split into finer sub-topics. The distant scatter is noise for our purposes.\n\n**The approach:** use the 2D UMAP projection from Section 6 as a spatial proxy:\n1. Find the mega-topic (largest non-outlier cluster)\n2. Compute its centroid and the **95th percentile** of distances from the centroid\n3. Draw a circle at `P95 × margin` — everything outside gets dropped\n4. Re-cluster only the surviving core documents\n\n**Why P95 instead of max?** The mega-topic often has a few straggler points far from the dense core. Using the max distance would make the circle huge and capture almost everything. The 95th percentile defines the boundary of where most of the mega-topic actually lives."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Step 1: Identify the mega-topic and compute its spatial extent ──\n\ntopic_arr = np.array(topics)\n\n# Find the largest non-outlier topic\ntopic_counts = pd.Series(topics).value_counts()\nif -1 in topic_counts.index:\n    topic_counts = topic_counts.drop(-1)\nmega_topic_id = topic_counts.idxmax()\nmega_count = topic_counts[mega_topic_id]\n\nprint(f\"Mega-topic: Topic {mega_topic_id}  ({mega_count} docs, \"\n      f\"{mega_count/len(topics)*100:.1f}% of corpus)\")\n\n# Get 2D positions of the mega-topic documents\nmega_mask = topic_arr == mega_topic_id\nmega_points = reduced_embeddings[mega_mask]\n\n# Centroid of the mega-topic\ncentroid = mega_points.mean(axis=0)\ndistances_mega = np.linalg.norm(mega_points - centroid, axis=1)\n\n# Use a PERCENTILE-based radius instead of max distance.\n# The max is too sensitive to a few straggler points within the mega-topic\n# that sit far from the dense core. The 95th percentile captures the bulk\n# of the mega-topic while ignoring those outliers.\nPERCENTILE = 95\nMARGIN = 1.15   # 15% padding beyond the percentile boundary\n\np95_dist = np.percentile(distances_mega, PERCENTILE)\nradius = p95_dist * MARGIN\n\nprint(f\"\\nDistance distribution within mega-topic:\")\nprint(f\"  Median:  {np.median(distances_mega):.2f}\")\nprint(f\"  P95:     {p95_dist:.2f}\")\nprint(f\"  Max:     {distances_mega.max():.2f}\")\nprint(f\"\\nFilter radius = P{PERCENTILE} × {MARGIN} = {radius:.2f}\")\nprint(f\"  (Using max would give {distances_mega.max() * MARGIN:.2f} — way too large)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Step 2: Visualize the spatial cut ──────────────────────────────\nall_distances = np.linalg.norm(reduced_embeddings - centroid, axis=1)\nkeep_mask = all_distances <= radius\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Plot all documents, colored by keep/remove\nax.scatter(\n    reduced_embeddings[~keep_mask, 0],\n    reduced_embeddings[~keep_mask, 1],\n    c=\"lightgray\", s=3, alpha=0.4, label=f\"Removed ({(~keep_mask).sum()})\",\n)\nax.scatter(\n    reduced_embeddings[keep_mask & ~mega_mask, 0],\n    reduced_embeddings[keep_mask & ~mega_mask, 1],\n    c=\"steelblue\", s=4, alpha=0.5, label=f\"Kept (non-mega, {(keep_mask & ~mega_mask).sum()})\",\n)\nax.scatter(\n    mega_points[:, 0],\n    mega_points[:, 1],\n    c=\"darkorange\", s=4, alpha=0.5, label=f\"Mega-topic ({mega_count})\",\n)\n\n# Draw the filter circle\ncircle = plt.Circle(\n    centroid, radius, fill=False, color=\"red\", linewidth=2, linestyle=\"--\"\n)\nax.add_patch(circle)\nax.plot(*centroid, \"r+\", markersize=15, markeredgewidth=2)  # centroid marker\n\nax.set_aspect(\"equal\")\nax.legend(loc=\"upper right\", fontsize=10)\nax.set_title(\n    f\"Spatial filter: keep documents within {radius:.1f} of mega-topic centroid\",\n    fontsize=13,\n)\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nDocuments kept:    {keep_mask.sum()} ({keep_mask.mean()*100:.1f}%)\")\nprint(f\"Documents removed: {(~keep_mask).sum()} ({(~keep_mask).mean()*100:.1f}%)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Step 3: Re-cluster the spatially filtered pool ─────────────────\ndf_pool = df_sample[keep_mask].reset_index(drop=True)\nembeddings_pool = embeddings[keep_mask]\n\nprint(f\"Re-clustering {len(df_pool)} documents (dropped {(~keep_mask).sum()} distant docs)\\n\")\n\n# After spatial filtering the pool is smaller and more homogeneous —\n# we need FINER clustering parameters to tease apart sub-topics.\numap_model_2 = UMAP(\n    n_neighbors=10,       # smaller neighborhood → preserves local structure better\n    n_components=5,\n    min_dist=0.0,\n    metric=\"cosine\",\n    random_state=42,\n)\n\nhdbscan_model_2 = HDBSCAN(\n    min_cluster_size=15,  # lowered: the filtered pool is denser, need finer splits\n    min_samples=3,        # lowered: allow less-dense sub-clusters to form\n    metric=\"euclidean\",\n    cluster_selection_method=\"eom\",\n    prediction_data=True,\n)\n\n# Fresh vectorizer for the smaller filtered pool — lower min_df to avoid\n# \"max_df corresponds to < documents than min_df\" on small topic subsets\nvectorizer_2 = CountVectorizer(\n    stop_words=stopwords,\n    ngram_range=(1, 2),\n    min_df=2,\n)\n\ntopic_model = BERTopic(\n    embedding_model=embedding_model,\n    vectorizer_model=vectorizer_2,\n    umap_model=umap_model_2,\n    hdbscan_model=hdbscan_model_2,\n    representation_model=KeyBERTInspired(),\n    calculate_probabilities=True,\n    verbose=True,\n)\n\ntopics, probs = topic_model.fit_transform(\n    df_pool[\"text_clean\"].tolist(),\n    embeddings=embeddings_pool,\n)\n\n# BERTopic best-practice: explicitly reduce remaining outliers\noutliers_before = int(np.sum(np.array(topics) == -1))\nif outliers_before > 0:\n    topics = topic_model.reduce_outliers(\n        df_pool[\"text_clean\"].tolist(),\n        topics,\n        strategy=\"embeddings\",\n        embeddings=embeddings_pool,\n    )\n    topic_model.update_topics(\n        df_pool[\"text_clean\"].tolist(),\n        topics=topics,\n        vectorizer_model=vectorizer_2,\n    )\n\noutliers_after = int(np.sum(np.array(topics) == -1))\nprint(f\"Outliers: {outliers_before} → {outliers_after} after reduce_outliers(strategy='embeddings')\")\n\n# Update main variables so downstream cells use refined assignments\ndf_sample = df_pool\nembeddings = embeddings_pool\n\n# Pre-compute 2D embeddings for plotting (on the filtered pool)\nreduced_embeddings = UMAP(\n    n_neighbors=10,\n    n_components=2,\n    min_dist=0.0,\n    metric=\"cosine\",\n    random_state=42,\n).fit_transform(embeddings)\n\nprint(f\"\\nFinal refined topics: {len(set(topics)) - (1 if -1 in topics else 0)}\")\nprint(topic_model.get_topic_info().head(15).to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualize refined topics ──────────────────────────────────────\n",
    "topic_model.visualize_barchart(top_n_topics=12, n_words=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. LLM-Powered Topic Naming\n\nThe keyword-based topic names from BERTopic are functional but not always intuitive. We use **direct LLM calls** via Groq to generate descriptive topic names.\n\nThe approach:\n1. For each topic, collect its **top keywords** and a few **representative documents** from BERTopic\n2. Send them to `moonshotai/kimi-k2-instruct` with a naming prompt\n3. Use the response as the topic label\n\nNow that we have **refined, substantial topics** (from Section 7), the LLM naming works much better — each topic has enough documents to provide clear, representative samples.\n\n### Avoiding rate limits\n\nGroq's free tier has strict token-per-minute (TPM) limits. To stay within limits:\n- **Truncate documents** to ~500 characters (saves tokens)\n- **Pause 2 seconds** between API calls to respect TPM limits\n- **Send only 3 representative docs** per topic"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Set up Groq client for LLM topic naming ──────────────────────\nimport openai\nfrom bertopic.representation import OpenAI as OpenAIRepresentation\n\nGROQ_API_KEY = \"\"  # @param {type:\"string\"}\n\n# If not set above, try Colab secrets → then environment variable\nif not GROQ_API_KEY:\n    try:\n        from google.colab import userdata\n        GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n    except (ImportError, Exception):\n        GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\", \"\")\n\ngroq_client = openai.OpenAI(\n    api_key=GROQ_API_KEY,\n    base_url=\"https://api.groq.com/openai/v1\",\n)\n\n# Model choice: kimi-k2-instruct does much better topic naming than gpt-oss-20b\nLLM_MODEL = \"moonshotai/kimi-k2-instruct\"\n\n# Quick connectivity test\nresp = groq_client.chat.completions.create(\n    model=LLM_MODEL,\n    messages=[{\"role\": \"user\", \"content\": \"Say 'ready' in one word.\"}],\n    max_tokens=5,\n)\nprint(f\"Model: {LLM_MODEL} — {resp.choices[0].message.content}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Set up Groq client for LLM topic naming ──────────────────────\nimport openai\n\nGROQ_API_KEY = \"\"  # @param {type:\"string\"}\n\n# If not set above, try Colab secrets → then environment variable\nif not GROQ_API_KEY:\n    try:\n        from google.colab import userdata\n        GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n    except (ImportError, Exception):\n        GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\", \"\")\n\ngroq_client = openai.OpenAI(\n    api_key=GROQ_API_KEY,\n    base_url=\"https://api.groq.com/openai/v1\",\n)\n\n# Model choice: kimi-k2-instruct does much better topic naming than gpt-oss-20b\nLLM_MODEL = \"moonshotai/kimi-k2-instruct\"\n\n# Quick connectivity test\nresp = groq_client.chat.completions.create(\n    model=LLM_MODEL,\n    messages=[{\"role\": \"user\", \"content\": \"Say 'ready' in one word.\"}],\n    max_tokens=5,\n)\nprint(f\"Model: {LLM_MODEL} — {resp.choices[0].message.content}\")\n\n\ndef name_topic_with_llm(topic_id, topic_model, docs, topics_list, max_docs=3, doc_length=500):\n    \"\"\"Generate a descriptive name for a topic using direct LLM calls.\n\n    We call the LLM directly instead of using BERTopic's built-in OpenAI\n    integration, which has version-specific tokenizer compatibility issues.\n    \"\"\"\n    # Get topic keywords from BERTopic\n    topic_words = topic_model.get_topic(topic_id)\n    if not topic_words:\n        return f\"Topic {topic_id}\"\n    keywords = \", \".join([w for w, _ in topic_words[:10]])\n\n    # Get representative documents for this topic\n    topic_docs = [docs[i] for i, t in enumerate(topics_list) if t == topic_id]\n    sample_docs = topic_docs[:max_docs]\n    docs_text = \"\\n\".join(f\"- {d[:doc_length]}\" for d in sample_docs)\n\n    prompt = f\"\"\"I will provide you with sample texts and keywords from a topic cluster.\nCreate a concise, descriptive name (3-6 words) that captures the topic's essence.\n\nRequirements:\n- Use clear, specific language\n- Focus on the core theme, not peripheral details\n- Use natural phrasing (avoid generic words like \"issues\" or \"topics\")\n\nSample texts from this topic:\n{docs_text}\n\nKeywords: {keywords}\n\nOutput ONLY the topic name. No explanations. No preamble. Just the topic name:\"\"\"\n\n    try:\n        resp = groq_client.chat.completions.create(\n            model=LLM_MODEL,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=30,\n            temperature=0.1,\n        )\n        name = resp.choices[0].message.content.strip().strip('\"').strip(\"'\")\n        return name if name else f\"Topic {topic_id}\"\n    except Exception as e:\n        print(f\"  ⚠ LLM naming failed for topic {topic_id}: {e}\")\n        return f\"Topic {topic_id}\"\n\n\nprint(f\"\\nLLM topic naming function ready (direct API calls)\")\nprint(f\"  Model: {LLM_MODEL}\")\nprint(f\"  max_docs: 3 per topic, doc_length: 500 chars\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Apply LLM names to refined topic model ───────────────────────\n# We call the LLM directly for each topic instead of using BERTopic's\n# built-in OpenAI representation model (which has version-specific\n# tokenizer compatibility issues with some API providers).\n\ntopic_info = topic_model.get_topic_info()\nnon_outlier = topic_info[topic_info[\"Topic\"] != -1]\nn_topics = len(non_outlier)\nprint(f\"Naming {n_topics} refined topics with LLM (this takes a moment)...\\n\")\n\ntopic_labels = {}\ndocs_list = df_sample[\"text_clean\"].tolist()\n\nfor _, row in non_outlier.iterrows():\n    tid = row[\"Topic\"]\n    name = name_topic_with_llm(tid, topic_model, docs_list, topics)\n    topic_labels[tid] = name\n    print(f\"  Topic {tid:3d} ({row['Count']:4d} docs): {name}\")\n    time.sleep(2)  # Respect Groq TPM limits\n\n# Set clean custom labels for DataMapPlot and other visualizations\ntopic_model.set_topic_labels(topic_labels)\nprint(f\"\\nCustom labels set for {len(topic_labels)} topics.\")\n\n# Re-visualize with LLM names\ntopic_model.visualize_barchart(top_n_topics=10, n_words=8, custom_labels=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8b. Topic Maps with DataMapPlot (Static + Interactive)\n",
    "\n",
    "DataMapPlot supports two complementary outputs:\n",
    "\n",
    "- **Static map** (`interactive=False`) for lecture slides, papers, and reports\n",
    "- **Interactive map** (`interactive=True`) for exploratory analysis in notebooks\n",
    "\n",
    "We will generate both from the same refined topic model and save a high-resolution static image to `notebooks/figures/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── DataMapPlot: static figure + interactive view ─────────────────\nfrom pathlib import Path\n\n# 1) Static map for slides/reports\n# Size is controlled by width/height (pixels) at the BERTopic level.\n# All other styling goes through datamap_kwds → datamapplot.create_plot().\nfig_static = topic_model.visualize_document_datamap(\n    df_sample[\"text_clean\"].tolist(),\n    reduced_embeddings=reduced_embeddings,\n    custom_labels=True,\n    title=\"Moltbook Topic Landscape\",\n    sub_title=\"BERTopic clusters with LLM-generated names\",\n    width=800,\n    height=800,\n    interactive=False,\n    datamap_kwds=dict(\n        label_font_size=12,            # bigger label text (default auto)\n        dynamic_label_size=False,      # uniform label sizing\n        label_wrap_width=20,           # more chars before wrapping (default 16)\n        point_size=5,                  # marker size\n        force_matplotlib=True,         # needed for point_size > 3\n    ),\n)\n\noutput_dir = Path(\"notebooks/figures\")\noutput_dir.mkdir(parents=True, exist_ok=True)\nstatic_path = output_dir / \"nb04_datamap_static.png\"\nfig_static.savefig(static_path, dpi=300, bbox_inches=\"tight\")\nprint(f\"Saved static DataMapPlot: {static_path}\")\nplt.show()\n\n# 2) Interactive map for drill-down exploration\ntopic_model.visualize_document_datamap(\n    df_sample[\"text_clean\"].tolist(),\n    reduced_embeddings=reduced_embeddings,\n    custom_labels=True,\n    title=\"Moltbook Topic Landscape\",\n    sub_title=\"Click clusters to explore — hover for document text\",\n    interactive=True,\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparing Topics to Ground Truth\n",
    "\n",
    "Moltbook posts have ground-truth `topic_label` categories (A-I). Topic modeling is **unsupervised** — it does not know about these labels. But we can check whether the discovered topics align with the known categories using a cross-tabulation.\n",
    "\n",
    "A strong alignment means BERTopic found meaningful structure. Mismatches might reveal sub-topics within categories or cross-cutting themes that span multiple categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Cross-tabulation: discovered topics vs ground truth ───────────\n",
    "df_sample[\"topic\"] = topics\n",
    "\n",
    "if \"topic_label\" in df_sample.columns:\n",
    "    # Show cross-tab for top 15 topics (excluding outliers)\n",
    "    df_assigned = df_sample[df_sample[\"topic\"] != -1].copy()\n",
    "\n",
    "    # Limit to top 15 topics by size for readability\n",
    "    top_topics = df_assigned[\"topic\"].value_counts().head(15).index.tolist()\n",
    "    df_top = df_assigned[df_assigned[\"topic\"].isin(top_topics)]\n",
    "\n",
    "    ct = pd.crosstab(\n",
    "        df_top[\"topic_label\"],\n",
    "        df_top[\"topic\"],\n",
    "        margins=True,\n",
    "    )\n",
    "    print(\"Cross-tabulation: Ground-truth category (rows) vs BERTopic topic (columns)\")\n",
    "    print()\n",
    "    print(ct.to_string())\n",
    "else:\n",
    "    print(\"No 'topic_label' column found -- skipping comparison.\")\n",
    "    print(\"Topic distribution:\")\n",
    "    print(df_sample[\"topic\"].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercise: Tune the Model\n",
    "\n",
    "BERTopic is sensitive to hyperparameters. Change one or more settings and inspect impact:\n",
    "\n",
    "- `min_cluster_size`: try 10, 20, 50\n",
    "- `MIN_TOPIC_SIZE` threshold in refinement: try 30, 50, 100\n",
    "- `n_neighbors`: try 5, 15, 30\n",
    "- `n_components`: try 3, 10\n",
    "- Embedding model swap:\n",
    "  - `intfloat/multilingual-e5-small` (current default)\n",
    "  - `paraphrase-multilingual-MiniLM-L12-v2`\n",
    "  - `paraphrase-multilingual-mpnet-base-v2`\n",
    "- `ngram_range`: try `(1, 3)`\n",
    "\n",
    "Compare: number of topics, outlier count, and topic coherence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── YOUR CODE HERE ─────────────────────────────────────────────────\n",
    "# Step 1: Change one or more parameters below\n",
    "\n",
    "# umap_model_v2 = UMAP(\n",
    "#     n_neighbors=??,       # try 5, 15, 30\n",
    "#     n_components=??,      # try 3, 5, 10\n",
    "#     metric=\"cosine\",\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "# hdbscan_model_v2 = HDBSCAN(\n",
    "#     min_cluster_size=??,  # try 10, 20, 50\n",
    "#     metric=\"euclidean\",\n",
    "#     cluster_selection_method=\"eom\",\n",
    "#     prediction_data=True,\n",
    "# )\n",
    "\n",
    "# Step 2: Build and fit a new topic model\n",
    "\n",
    "# topic_model_v2 = BERTopic(\n",
    "#     embedding_model=embedding_model,\n",
    "#     vectorizer_model=vectorizer,\n",
    "#     umap_model=umap_model_v2,\n",
    "#     hdbscan_model=hdbscan_model_v2,\n",
    "#     representation_model=KeyBERTInspired(),\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# topics_v2, probs_v2 = topic_model_v2.fit_transform(\n",
    "#     df_sample[\"text_clean\"].tolist(),\n",
    "#     embeddings=embeddings,\n",
    "# )\n",
    "\n",
    "# Step 3: Compare\n",
    "# print(f\"Number of topics: {len(set(topics_v2)) - 1}\")\n",
    "# print(f\"Outliers: {sum(t == -1 for t in topics_v2)}\")\n",
    "# topic_model_v2.get_topic_info().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Summary & Takeaways\n\n### What we learned\n\n1. **Case framing matters.** In Moltbook, the mega-topic holds rich mixed discourse worth splitting, while scattered distant clusters are often platform noise.\n2. **Spatial filtering is a powerful refinement tool.** Using the 2D UMAP projection to define a \"keep zone\" around the mega-topic centroid is a simple, visual, and effective way to focus the analysis on the core discourse.\n3. **BERTopic is iterative.** A single pass is rarely enough; the inspect → spatial filter → re-cluster workflow produces much cleaner topics.\n4. **Outlier handling should be explicit.** Using `reduce_outliers` improves topic coverage after re-clustering.\n5. **LLM naming improves interpretability.** Topic labels become presentation-ready for downstream analysis.\n6. **DataMapPlot should be delivered in two modes.** Static output for publication, interactive output for exploration.\n\n### The spatial filtering workflow\n\n```\nFirst pass (broad)\n  → 2D UMAP visualization\n  → Identify mega-topic (largest cluster)\n  → Compute centroid + max radius + margin\n  → Draw circle, drop everything outside\n  → Re-cluster the filtered core\n  → LLM naming on refined topics\n```\n\n### Practical checklist\n\n- Start with conservative preprocessing.\n- Use the 2D UMAP projection to visually inspect the first-pass clustering.\n- Identify the mega-topic and use its spatial extent to filter noise.\n- Re-cluster only the core documents for sharper sub-topics.\n- Export both static and interactive maps.\n\n### Maker tutorials and references\n\n- BERTopic quickstart: https://maartengr.github.io/BERTopic/getting_started/quickstart/quickstart.html\n- BERTopic parameter tuning: https://maartengr.github.io/BERTopic/getting_started/parameter%20tuning/parametertuning.html\n- BERTopic outlier reduction: https://maartengr.github.io/BERTopic/getting_started/outlier_reduction/outlier_reduction.html\n- BERTopic DataMapPlot: https://maartengr.github.io/BERTopic/getting_started/datamapplot/datamapplot.html\n\n### Next steps\n\n- Use `merge_topics` to simplify overlapping clusters.\n- Experiment with different margin values (1.05 to 1.30) to see how aggressively filtering affects topic quality.\n- Compare topic purity before/after spatial filtering with `topic_label` cross-tabs."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio B: Topic Discovery\n",
    "**Map the conversation landscape of an AI agent social network**\n",
    "\n",
    "Moltbook is a leaked social network where AI agents post about everything from philosophy to memes. Your mission: use topic modeling to discover *what* agents talk about, *how* topics relate to each other, and whether the ground-truth labels capture the full picture.\n",
    "\n",
    "**Dataset**: Moltbook (44K AI agent posts, 9 ground-truth categories)  \n",
    "**Your goal**: Discover topics with BERTopic, name them with an LLM, and compare to ground-truth labels.\n",
    "\n",
    "### Deliverables\n",
    "- BERTopic model with tuned parameters\n",
    "- LLM-generated topic names\n",
    "- Visualization: topic map + at least one other\n",
    "- Cross-tabulation: discovered topics vs ground-truth labels\n",
    "- Brief model card\n",
    "\n",
    "**Estimated time**: Sprint 1 (55 min) + Sprint 2 (90 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets sentence-transformers bertopic umap-learn hdbscan openai scikit-learn matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"TrustAIRLab/Moltbook\", \"posts\", split=\"train\")\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "df[\"title\"] = df[\"post\"].apply(lambda x: x.get(\"title\", \"\") if isinstance(x, dict) else \"\")\n",
    "df[\"content\"] = df[\"post\"].apply(lambda x: x.get(\"content\", \"\") if isinstance(x, dict) else \"\")\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\").astype(str)\n",
    "df[\"content\"] = df[\"content\"].fillna(\"\").astype(str)\n",
    "df[\"text\"] = (df[\"title\"].str.strip() + \" . \" + df[\"content\"].str.strip()).str.strip()\n",
    "df = df[df[\"text\"].str.len() > 10].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total posts: {len(df)}\")\n",
    "print(f\"\\nGround-truth categories:\")\n",
    "print(df[\"topic_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https?://\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n",
    "df = df[df[\"text_clean\"].str.len() > 3].reset_index(drop=True)\n",
    "\n",
    "# Subsample for speed — increase if you have time\n",
    "df_sample = df.sample(5000, random_state=42).reset_index(drop=True)\n",
    "print(f\"Working with {len(df_sample)} posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encode Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.encode(df_sample[\"text_clean\"].tolist(), show_progress_bar=True, batch_size=64)\n",
    "print(f\"Embeddings: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline BERTopic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "stopwords = list(ENGLISH_STOP_WORDS) + [\n",
    "    \"just\", \"like\", \"really\", \"think\", \"know\", \"want\",\n",
    "    \"got\", \"get\", \"one\", \"would\", \"could\", \"also\",\n",
    "    \"ai\", \"agent\", \"agents\", \"moltbook\", \"post\", \"posts\",\n",
    "    \"bot\", \"bots\", \"human\", \"humans\",\n",
    "]\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=CountVectorizer(stop_words=stopwords, ngram_range=(1, 2), min_df=5),\n",
    "    umap_model=UMAP(n_neighbors=15, n_components=5, metric=\"cosine\", random_state=42),\n",
    "    hdbscan_model=HDBSCAN(min_cluster_size=50, min_samples=10, prediction_data=True),\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(df_sample[\"text_clean\"].tolist(), embeddings=embeddings)\n",
    "print(f\"\\nTopics found: {len(set(topics)) - 1}\")\n",
    "print(f\"Outliers: {sum(t == -1 for t in topics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics=12, n_words=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Your Turn: Tune & Improve\n",
    "\n",
    "Try changing these parameters and see how the topics change:\n",
    "- `min_cluster_size`: smaller = more topics, larger = fewer broad topics\n",
    "- `n_neighbors`: affects how local/global the UMAP structure is\n",
    "- `min_df` in CountVectorizer: filter rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — Try different parameters\n",
    "# topic_model_v2 = BERTopic(\n",
    "#     ...\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Your Turn: LLM Topic Naming\n",
    "Use Groq to give topics human-readable names (see NB04 for the full pattern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — LLM topic naming via Groq\n",
    "# import openai\n",
    "# from bertopic.representation import OpenAI as OpenAIRepresentation\n",
    "#\n",
    "# GROQ_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "# groq_client = openai.OpenAI(api_key=GROQ_API_KEY, base_url=\"https://api.groq.com/openai/v1\")\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare to Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample[\"topic\"] = topics\n",
    "df_assigned = df_sample[df_sample[\"topic\"] != -1].copy()\n",
    "top_topics = df_assigned[\"topic\"].value_counts().head(10).index.tolist()\n",
    "df_top = df_assigned[df_assigned[\"topic\"].isin(top_topics)]\n",
    "\n",
    "ct = pd.crosstab(df_top[\"topic_label\"], df_top[\"topic\"], margins=True)\n",
    "print(ct.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic map\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — try visualize_documents(), visualize_hierarchy(), or visualize_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Card\n",
    "\n",
    "| Field | Value |\n",
    "|-------|-------|\n",
    "| **Task** | Topic discovery on AI agent posts |\n",
    "| **Dataset** | Moltbook (N=5000 sample) |\n",
    "| **Topics found** | _number_ |\n",
    "| **Outlier rate** | _percentage_ |\n",
    "| **Best insight** | _what did you discover?_ |\n",
    "| **Ground-truth match** | _do topics align with the 9 labels?_ |\n",
    "| **Weakness** | _what topics are confused or missing?_ |\n",
    "| **Improvement idea** | _what you'd try next_ |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}